import pandas as pd
import vertica_python
import numpy as np
import sys
sys.path.append(r'C:\Users\danny.habetyes\Desktop\Code\Python\domo_api-master')
import domo_api
from datetime import datetime
import time

# Connection Info
conn_info = {'host': 'vertica.chotel.com',
             'port': '5433',
             'user': 'danny.habetyes',
             'password': 'Choice123',
             'database': 'choice_vertica_1',
             # autogenerated session label by default,
             'session_label': 'some_label',
             # default throw error on invalid UTF-8 results
             'unicode_error': 'strict',
             # SSL is disabled by default
             'ssl': False,
             # using server-side prepared statements is disabled by default
             'use_prepared_statements': False,
             'connection_timeout': 150}

# Define function to pull dataframes
def vertica_pull(sql_string, emails=True, save = True, save_file="rename", file_type =".csv"):
    """
    emails: Rewrites first column header to be "Emails" for hashed list uploading
    save: defaults to True. Set to False to avoid writing CSV
    file_type: defaults to .csv
    """
    with vertica_python.connect(**conn_info) as connection:
        cur = connection.cursor()
        get = cur.execute(sql_string)
        df = pd.DataFrame(get.fetchall(), columns = [x[0] for x in get.description])
        if emails:
                df = df.rename(columns={df.columns[0]:"Email"})
        while save:
            df.to_csv(f'{save_file}{file_type}', index=False)
            return print(f'File saved as {save_file}{file_type}')
        return df

sql2 ="""
WITH RESERVATIONS AS (
   select *
     from
   (
     select b.reservation_date
     , case when b.reservation_date between SYSDATE - 9 and SYSDATE -2 then '-7 Days'
     when b.reservation_date between (SYSDATE - 9)-364 and (SYSDATE -2)-364 then '-7 Days'
     when b.reservation_date between SYSDATE - 16 and SYSDATE -9 then '-14 Days'
     when b.reservation_date between (SYSDATE - 16)-364 and (SYSDATE -9)-364 then '-14 Days'
     when b.reservation_date between SYSDATE - 23 and SYSDATE -16 then '-21 Days'
     when b.reservation_date between (SYSDATE - 23)-364 and (SYSDATE -16)-364 then '-21 Days'
     else '-22 Days +' end as time_window
     , DATE_PART('MONTH', b.arrival_date) || '-' || DATE_PART('YEAR', b.arrival_date) as arrival_mo
     , DATE_PART('YEAR', b.reservation_date) as reservation_year
     , case when DATE_PART('YEAR', b.reservation_date) = '2020' then b.reservation_date
     else b.reservation_date+364 end as same_date
     , case when b.arrival_date - b.reservation_date <0 then 0
     else b.arrival_date - b.reservation_date end as AP_window   
     , case when b.arrival_date - b.reservation_date <0 then '0-1 Days'
     When b.arrival_date - b.reservation_date between 0 and 1 then '0-1 Days'
     When b.arrival_date - b.reservation_date between 2 and 3 then '2-3 Days'
     When b.arrival_date - b.reservation_date between 4 and 7 then '4-7 Days'
     When b.arrival_date - b.reservation_date between 8 and 14 then '8-14 Days'
     else '15+ Days' end as ABW  
     , b.conf_nbr
     , 1 as res_nbr                          
     , b.prop_city  
     , c.market_name
     , d.county_code
     , d.city
     , d.state
     , d.county_name
     , d.nielsen_dma 
     , p.mkt_location_des
     , b.prop_state
     , b.ta_client_id
     , i.iata_desc
     , i.media_desc           
     , row_number() over (partition by b.conf_nbr, b.ta_client_id, b.guest_city, b.prop_code order by b.reservation_date) as rn
    
     from public.prd_reservations b
     inner join rm.nc_srp_grouping_detail r on b.srp_code = r.srp_code
     inner join sandbox.da_iata_lookup i on i.iata = b.ta_client_id
     inner join public.current_property p on p.prop = b.prop_code
     inner join prd_prop_info_detail c on b.prop_code = c.prop    
     inner join sandbox.da_dma_lookup d on LEFT(c.zip, 5) = LEFT(d.zip_code, 5)    

     where 1=1
     and i.media_desc in ('Meta','Search')
     and b.prop_country in ('US')
     and b.reservation_date > '04-01-2018'
     and b.canx_nbr = '0'
    
     group by b.reservation_date
     , case when b.reservation_date between SYSDATE - 16 and SYSDATE -2 then 'Y'
     when b.reservation_date between (SYSDATE - 16)-364 and (SYSDATE -2)-364 then 'Y'
     else 'N' end 
     , DATE_PART('MONTH', b.arrival_date) || '-' || DATE_PART('YEAR', b.arrival_date) 
     , DATE_PART('YEAR', b.reservation_date) 
     , case when DATE_PART('YEAR', b.reservation_date) = '2020' then b.reservation_date
     else b.reservation_date+364 end 
     ,  case when b.arrival_date - b.reservation_date <0 then 0
     else b.arrival_date - b.reservation_date end 
     , b.conf_nbr                 
     , b.prop_city
     , c.market_name   
     , p.mkt_location_des
     , b.prop_state
     , d.county_code
     , d.city
     , d.state
     , d.county_name
     , d.nielsen_dma
     , b.ta_client_id
     , i.iata_desc
     , i.iata_desc
     , i.media_desc  
     , case when r.comission = 'Yes' then 'Y'
     when r.comission = 'No' then 'N'
     when r.srp_code like 'RACK%' then 'Y'
     when r.srp_code like '%GROUP%' then 'N'
     when r.srp_code like '%PKG%' then 'N'       
     else 'Y' end
     , case when b.arrival_date - b.reservation_date <0 then '0-1 Days'
     When b.arrival_date - b.reservation_date between 0 and 1 then '0-1 Days'
     When b.arrival_date - b.reservation_date between 2 and 3 then '2-3 Days'
     When b.arrival_date - b.reservation_date between 4 and 7 then '4-7 Days'
     When b.arrival_date - b.reservation_date between 8 and 14 then '8-14 Days'
     else '15+ Days' end                                          
     , b.guest_city
     , b.prop_code
    
     having case when r.comission = 'Yes' then 'Y'
     when r.comission = 'No' then 'N'
     when r.srp_code like 'RACK%' then 'Y'
     when r.srp_code like '%GROUP%' then 'N'
     when r.srp_code like '%PKG%' then 'N'       
     else 'Y' end = 'Y'          
   ) b
  
   where rn = 1
 ),


 REVENUE AS (
   select b.conf_nbr
   , round(sum(gross_resv),2) as gross_resv
   , round(sum(gross_nights),2) as gross_nights
   , round(sum(gross_revenue),2) as gross_revenue
   , round(sum(canx_resv),2) as canx_resv
   , round(sum(canx_nights),2) as canx_nights
   , round(sum(canx_revenue),2) as canx_revenue
   , round(sum(net_resv),2) as net_resv
   , round(sum(net_nights),2) as net_nights
   , round(sum(net_revenue),2) as net_revenue
  
   from public.prd_reservations b
   inner join rm.nc_srp_grouping_detail r on b.srp_code = r.srp_code
   inner join sandbox.da_iata_lookup i on i.iata = b.ta_client_id
   inner join public.current_property p on p.prop = b.prop_code   
  
   where 1=1
   and i.media_desc in ('Meta','Search')
   and b.prop_country in ('US')
   and b.reservation_date > '04-01-2018'
  
   group by b.conf_nbr                 
   , case when r.comission = 'Yes' then 'Y'
   when r.comission = 'No' then 'N'
   when r.srp_code like 'RACK%' then 'Y'
   when r.srp_code like '%GROUP%' then 'N'
   when r.srp_code like '%PKG%' then 'N'       
   else 'Y' end
  
   having case when r.comission = 'Yes' then 'Y'
   when r.comission = 'No' then 'N'
   when r.srp_code like 'RACK%' then 'Y'
   when r.srp_code like '%GROUP%' then 'N'
   when r.srp_code like '%PKG%' then 'N'       
   else 'Y' end = 'Y'          
 ),

 CANCELS AS (
   select b.conf_nbr
   , 1 as canx_nbr
  
   from public.prd_reservations b
   inner join rm.nc_srp_grouping_detail r on b.srp_code = r.srp_code
   inner join sandbox.da_iata_lookup i on i.iata = b.ta_client_id
   inner join public.current_property p on p.prop = b.prop_code   
  
   where 1=1
   and i.media_desc in ('Meta','Search')
   and b.prop_country in ('US')
   and b.reservation_date > '04-01-2018'
   and b.canx_nbr !='0'  
  
   group by b.conf_nbr                 
   , case when r.comission = 'Yes' then 'Y'
   when r.comission = 'No' then 'N'
   when r.srp_code like 'RACK%' then 'Y'
   when r.srp_code like '%GROUP%' then 'N'
   when r.srp_code like '%PKG%' then 'N'       
   else 'Y' end
  
   having case when r.comission = 'Yes' then 'Y'
   when r.comission = 'No' then 'N'
   when r.srp_code like 'RACK%' then 'Y'
   when r.srp_code like '%GROUP%' then 'N'
   when r.srp_code like '%PKG%' then 'N'       
   else 'Y' end = 'Y'   
 )

 Select reservation_date, county_code, county_name, (city|| ', ' ||state) as city, state, nielsen_dma, market_name, ABW, media_desc, SUM(gross_resv) as resv, SUM(canx_resv) as canx_resv, SUM(rv.gross_revenue) as rev 
   from RESERVATIONS rs
 inner join REVENUE rv on rs.conf_nbr = rv.conf_nbr
 left join CANCELS cn on rs.conf_nbr = cn.conf_nbr
 where rs.same_date between  '02-23-2020' and SYSDATE -2 AND reservation_date > '2020-02-23'
 GROUP BY 1,2,3,4,5,6,7,8,9
 ORDER BY reservation_date
"""
sql2 = sql2.replace("\n", "")

# create initial dataframe
print(f"Pulling Vertica: {str(datetime.now())}", flush=True)
df = vertica_pull(sql2, False, False)
print(f"Vertica Pull Complete: {str(datetime.now())}", flush=True)
df.rename(columns={"media_desc": "MEDIA_DESC", "gross_resv": "resv"}, inplace=True)
df = df[["reservation_date", "county_code", "county_name","city", "state", "nielsen_dma", "market_name", "ABW", "MEDIA_DESC", "resv", "canx_resv"]]
   
# Create dictionaries for each markets name, each channel, and each abw grouping
geos = df.city.unique()
geo_len = [x for x in range(1,len(geos)+1)]
geo_dict = dict(zip(geos, geo_len))
channel_dict = {"Search": "s", "Meta": "m"}
abws = df.ABW.unique()
abw_len = [x for x in range(1,len(abws)+1)]
abw_dict = dict(zip(abws, abw_len))

# Create sliced dataframes by location, channel and abw
df_list = []
print(f"Creating DFs: {str(datetime.now())}", flush=True)
for k,v in geo_dict.items():
    for s,m in channel_dict.items():
        for a,b in abw_dict.items():
            exec(f"m{v}_{s}_{b} = df.loc[(df.city == '{k}') & (df.MEDIA_DESC == \'{s}\') & (df.ABW == \'{a}\')]")
            df_list.append(f'm{v}_{s}_{b}')

def sub_split(df):
  for x in df.county_code.unique():
    exec(f'm{x} = df.loc[(df.county_code == \'{x}\')]')
    fill_rolling(df)

print(f"DFs Created: {str(datetime.now())}", flush=True)
# Fills gaps in individual dataframe days so rolling day counts are accurate.
def fill_rolling(df):
    df.set_index('reservation_date', drop=True, inplace=True)
    df.fillna(method='bfill', inplace=True)
    df.fillna(method='ffill', inplace=True)
    df = df.groupby(["reservation_date", "county_code", "county_name", "city", "state", "nielsen_dma", "market_name", "MEDIA_DESC", "ABW"]).sum()
    df.reset_index(level=["county_code", "county_name", "city", "state", "nielsen_dma", "market_name", "MEDIA_DESC", "ABW"], inplace=True)
    sample = pd.date_range('2020-02-23', datetime.date(datetime.now()))
    sample_list_dt = []
    sample_list_str = []
    for x in sample:
        sample_list_dt.append(datetime.date(x))
        sample_list_str.append(datetime.date(x).strftime("%Y-%m-%d"))
    constants = df[['county_code', 'county_name','city','state','nielsen_dma','market_name', 'ABW', 'MEDIA_DESC']]
    values = df[['resv', 'canx_resv']]
    try:
        constants = constants.reindex(sample_list_dt, method='ffill')
    except:
        constants = constants.reindex(sample_list_str, method='ffill')
    constants = constants.fillna(method='bfill')
    try:
        values = values.reindex(sample_list_dt, fill_value=0)
    except:
        values = values.reindex(sample_list_str, fill_value=0)
    final = constants.join(values)
    final['30_day_res'] = final['resv'].rolling(window=30, min_periods = 1).sum()
    final['30_day_canx'] = final['canx_resv'].rolling(window=30, min_periods = 1).sum()
    final['7_day_res'] = final['resv'].rolling(window=7, min_periods = 1).sum()
    final['7_day_canx'] = final['canx_resv'].rolling(window=7, min_periods = 1).sum()
    final = final.reset_index()
    return final

y = 1
# Create new dataframe for all segments and stitch them all together
stitched_df= pd.DataFrame(columns=['reservation_date', 'county_code', 'county_name','city','state','nielsen_dma', 'market_name', 'ABW', 'MEDIA_DESC', 'resv', 'canx_resv', '30_day_res', '30_day_canx', '7_day_res', '7_day_canx'])
print(f"Begin Filling DFs: {str(datetime.now())}", flush=True)
for x in df_list:
# Print a status update to console every 500 iterations
  if x in df_list[::500]:
    print(f'{df_list.index(x)} of {len(df_list)} Complete', flush=True)
# For cities that reside in multiple counties, split DFs, fill each and append, else just fill
  if len(eval(x).county_code.unique()) > 1:
    print(f'{y} cities with multiple counties', flush=True)
    y += 1
    for z in eval(x).county_code.unique():
      exec(f'm{z} = eval(x).loc[(df.county_code == \'{z}\')]')
      data = fill_rolling(eval(f'm{z}'))
      stitched_df = stitched_df.append(data)
  else:
    data = fill_rolling(eval(x))
    stitched_df = stitched_df.append(data)

print(f"DFs Filled: {str(datetime.now())}", flush=True)
stitched_df.to_csv(f'{datetime.date(datetime.now())}rolling_cancel_rates_new.csv', index=False)
print('csv saved')

# domo_api.create_datasets("ABW_Channel_cancel", "Rolling cancel rate by ABW", stitched_df)

try
domo_api.update_dataset("ABW_Channel_cancel", stitched_df)
print("Uploaded to Domo")
time.sleep(20)

